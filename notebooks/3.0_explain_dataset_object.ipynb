{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#A-Dataset-Object\" data-toc-modified-id=\"A-Dataset-Object-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>A Dataset Object</a></span></li><li><span><a href=\"#Compiling-pollution-data\" data-toc-modified-id=\"Compiling-pollution-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Compiling pollution data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "#  always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import src\n",
    "from src.imports import *\n",
    "from src.gen_functions import *\n",
    "# import the Dataset object class\n",
    "from src.features.dataset import Dataset\n",
    "from src.visualization.mapper import *\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Dataset Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is more convenience to have a `Dataset` object that keep tracks of all relavant data for a city along with necessary meta information such as city location etc. This is object is under `src.features.dataset.py`.\n",
    "\n",
    "The `Dataset` object is also in charge of compile raw pollution, weather, fire data from the data folder into a ready-to-use format using `dataset.build_all_data()`. The processed data are saved under ../data/city_name/. The code below illustrates how to `Dataset` object compile the data using a build_all_data command. This object also keep track of feature engineering parameters during the model optimization step[notebook](https://github.com/worasom/aqi_thailand2/blob/master/notebooks/5.0-ML_ChiangMai.ipynb). For the Dataset object's documentation, please refer to https://github.com/worasom/aqi_thailand2/blob/master/docs/_build/html/src.features.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th_stations ['35t', '36t']\n",
      "Averaging data from 3 stations\n",
      "Loading all hotspots data. This might take sometimes\n"
     ]
    }
   ],
   "source": [
    "# init a dataset object and build the data from scratch \n",
    "# only perform this when new data files are added \n",
    "dataset = Dataset('Chiang Mai')\n",
    "\n",
    "# build pollution,  weather data and (optional) fire data\n",
    "dataset.build_all_data( build_fire=True, build_holiday=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.build_all_data()` calls four functions: \n",
    "- `dataset.build_pollution()`: compiles pollution data form all available sources, averages all the pollution data, and add as `dataset.poll_df` attribute. \n",
    "- `dataset.build_weather()`: load weather data, fills the missing, and add as `dataset.wea`.\n",
    "- `dataset.build_fire()`: Compile the satellite data files into a `dataset.fire` dataframe.\n",
    "- `dataset.build_holiday()`: scrapes holiday information from the website and save as a csv file. \n",
    "    \n",
    "These function can be called separately when needing to update any data.\n",
    "\n",
    "After the building process, which might take sometimes because of the size of the fire data (building the fire data is optional and can be set to false (`build_fire=False`). The complied data can be loaded using `_load()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved process data \n",
    "dataset = Dataset('Chiang Mai')\n",
    "dataset.load_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hourly pollution data, weather data, and fire data are under `dataset.poll_df`, `dataset.wea` and `dataset.fire` attributes accordingly. Each data is a panda dataframe with datetime index. For example, the pollution data for Chiang Mai looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| datetime            |   PM2.5 |   PM10 |   O3 |   CO |   NO2 |   SO2 |\n",
      "|:--------------------|--------:|-------:|-----:|-----:|------:|------:|\n",
      "| 2020-06-17 15:00:00 |     8.5 |   19.5 |   15 | 0.4  |     5 |     1 |\n",
      "| 2020-06-17 16:00:00 |     7.5 |   16.5 |   11 | 0.43 |     5 |     1 |\n"
     ]
    }
   ],
   "source": [
    "print(dataset.poll_df.tail(2).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally the dataset also has city information under `city_info` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': 'Thailand',\n",
       " 'City': 'Chiang Mai',\n",
       " 'City (ASCII)': 'Chiang Mai',\n",
       " 'Region': 'Chiang Mai',\n",
       " 'Region (ASCII)': 'Chiang Mai',\n",
       " 'Population': '200952',\n",
       " 'Latitude': '18.7904',\n",
       " 'Longitude': '98.9847',\n",
       " 'Time Zone': 'Asia/Bangkok',\n",
       " 'lat_km': 2117.0,\n",
       " 'long_km': 11019.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.city_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling pollution data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset.build_pollution()` compiles data from many data sources and average them into a single dataframe under `dataset.poll_df` attribute. Internally, this function calls `dataset.collect_stations_data()` for a list of pollution dataframes from different sources. It calls many functions in `src.data.read_data.py`. Here, I will explain `dataset.collect_stations_data()` function. \n",
    "\n",
    "Below is the definition of this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def collect_stations_data(self):\n",
    "        \"\"\"Collect all Pollution data from a different sources and take the average.\n",
    "\n",
    "        Since each city have different data sources. It has to be treat differently. \n",
    "        The stations choices is specified by the config.json\n",
    "\n",
    "        Returns: a list of dataframe each dataframe is the data from all station.\n",
    "\n",
    "        \"\"\"\n",
    "        # data list contain the dataframe of all pollution data before merging\n",
    "        # all of this data has 'datetime' as a columns\n",
    "        data_list = []\n",
    "\n",
    "        # load data from Berkeley Earth Projects This is the same for all cities\n",
    "        b_data, _ = read_b_data(self.main_folder + 'pm25/' + self.city_name.replace(' ', '_') + '.txt')\n",
    "        data_list.append(b_data)\n",
    "\n",
    "        try:\n",
    "            # load config_dict for the city \n",
    "            config_dict = self.config_dict[self.city_name]\n",
    "        except:\n",
    "            config_dict = {}\n",
    "        \n",
    "        # load thailand stations if applicable \n",
    "        if 'th_stations' in config_dict.keys():\n",
    "            station_ids = config_dict['th_stations']\n",
    "            print('th_stations', station_ids)\n",
    "            self.merge_new_old_pollution(station_ids)\n",
    "            # load the file\n",
    "            for station_id in station_ids:\n",
    "                filename = self.data_folder + station_id + '.csv'\n",
    "                data = pd.read_csv(filename)\n",
    "                data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "                data_list.append(data)\n",
    "        # load the Thailand stations maintained by cmucdc project \n",
    "        if 'cmu_stations' in config_dict.keys():\n",
    "            station_ids = config_dict['cmu_stations']\n",
    "            print('cmu_stations', station_ids)\n",
    "            for station_id in station_ids:\n",
    "                filename = self.main_folder + 'cdc_data/' + str(station_id) + '.csv' \n",
    "                data_list.append(read_cmucdc(filename))\n",
    "        \n",
    "        if 'b_stations' in config_dict.keys():\n",
    "            # add Berkeley stations in near by provinces \n",
    "            station_ids = config_dict['b_stations']\n",
    "            print('add Berkerley stations', station_ids)\n",
    "            for station_id in station_ids:\n",
    "                b_data, _ = read_b_data(self.main_folder + 'pm25/' + f'{station_id}.txt')\n",
    "                data_list.append(b_data)\n",
    "\n",
    "        if 'us_emb' in config_dict.keys():\n",
    "            # add the data from US embassy \n",
    "            print('add US embassy data')\n",
    "            data_list += build_us_em_data(city_name=self.city_name,\n",
    "                                                    data_folder=f'{self.main_folder}us_emb/')\n",
    "\n",
    "        return data_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`src.data.read_data.read_b_data()` loads the [Berkeley project](http://berkeleyearth.org/) data using the `self.city_name`. This data is common for all the cities. For the other data sources, the availability varies, so it must be specified in `src.features.config.py`. The dictionary in this function is added as `dataset.conf_dict` attribute. \n",
    "\n",
    "For example for **Chiang Mai**, it says "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiang Mai stations  {'th_stations': ['35t', '36t']}\n"
     ]
    }
   ],
   "source": [
    "print('Chiang Mai stations ', dataset.config_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for Chiang Mai, include the data form two Thailand DPC stations: '35t', '36t', in addition to the Berkeley project data. The function dataset.merge_new_old_pollution() compiled the historical data and scraped data for each station and save under `../data/city_name/` folder. The merged data is then read and append to the data_list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **Nakhon Si Thammarat**, the config_dict says"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nakhon Si Thammarat {'th_stations': ['42t', 'm3'], 'cmu_stations': [118]}\n"
     ]
    }
   ],
   "source": [
    "print('Nakhon Si Thammarat', dataset.config_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Nakhon Si Thammarat, I borrow the data from the near by province (station '42t'), in addition to the mobile station 'm3'. Then I also include the data from [Chiang Mai University Monitoring Stations](https://www.cmuccdc.org/), station number 118. This is done by calling `src.data.read_data.read_cmucdc()`\n",
    "\n",
    "To check for Thailand DPC's stations number, use `src.data.read_data.get_th_stations()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['35t', '36t'],\n",
       " [{'stationID': '35t',\n",
       "   'nameTH': 'ศูนย์ราชการจังหวัดเชียงใหม่ ',\n",
       "   'nameEN': 'City Hall, Chiangmai',\n",
       "   'areaTH': 'ต.ช้างเผือก อ.เมือง, เชียงใหม่',\n",
       "   'areaEN': 'Chang Phueak, Meuang, Chiang Mai',\n",
       "   'stationType': 'GROUND',\n",
       "   'lat': '18.840633',\n",
       "   'long': '98.969661',\n",
       "   'LastUpdate': {'date': '2020-09-17',\n",
       "    'time': '23:00',\n",
       "    'PM25': {'value': '15', 'unit': 'µg/m³'},\n",
       "    'PM10': {'value': '27', 'unit': 'µg/m³'},\n",
       "    'O3': {'value': '18', 'unit': 'ppb'},\n",
       "    'CO': {'value': '-', 'unit': 'ppm'},\n",
       "    'NO2': {'value': '0', 'unit': 'ppb'},\n",
       "    'SO2': {'value': '0', 'unit': 'ppb'},\n",
       "    'AQI': {'Level': '1', 'aqi': '15'}}},\n",
       "  {'stationID': '36t',\n",
       "   'nameTH': 'โรงเรียนยุพราชวิทยาลัย ',\n",
       "   'nameEN': 'Yupparaj Wittayalai School',\n",
       "   'areaTH': 'ต.ศรีภูมิ อ.เมือง, เชียงใหม่',\n",
       "   'areaEN': 'Si Phum, Meuang, Chiang Mai',\n",
       "   'stationType': 'GROUND',\n",
       "   'lat': '18.7909205',\n",
       "   'long': '98.9881062',\n",
       "   'LastUpdate': {'date': '2020-09-17',\n",
       "    'time': '23:00',\n",
       "    'PM25': {'value': '9', 'unit': 'µg/m³'},\n",
       "    'PM10': {'value': '24', 'unit': 'µg/m³'},\n",
       "    'O3': {'value': 'N/A', 'unit': 'ppb'},\n",
       "    'CO': {'value': '0.46', 'unit': 'ppm'},\n",
       "    'NO2': {'value': '-', 'unit': 'ppb'},\n",
       "    'SO2': {'value': '1', 'unit': 'ppb'},\n",
       "    'AQI': {'Level': '1', 'aqi': '12'}}}])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.data.read_data.get_th_stations('Chiang Mai')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For [Chiang Mai University Monitoring Stations](https://www.cmuccdc.org/), one can search for the station ids from their json file. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['118']\n"
     ]
    }
   ],
   "source": [
    "station_info_list = requests.get('https://www.cmuccdc.org/api/ccdc/stations').json()\n",
    "\n",
    "station_ids= []\n",
    "for station in station_info_list:\n",
    "    if 'Nakhon Si Thammarat' in station['dustboy_name_en']:\n",
    "        station_ids.append(station['dustboy_id'])\n",
    "\n",
    "print(station_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **Hanoi**, the configuration file says"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanoi stations  {'b_stations': ['Ha_Dong'], 'us_emb': True}\n"
     ]
    }
   ],
   "source": [
    "print('Hanoi stations ', dataset.config_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
